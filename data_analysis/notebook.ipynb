{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total PUT/GET Per Peer Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validator PUT/GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? Get all validators total stats\n",
    "validator_total_stats_files = [file for file in os.listdir(data_dir) if file.endswith('total_stats_validator.csv')]\n",
    "\n",
    "total_stats_df = pd.DataFrame(columns=[\"peer_id\", \"total_gets\", \"failed_gets\", \"successful_gets\"])\n",
    "\n",
    "for file in validator_total_stats_files:\n",
    "    peer_id = file.split(\"_\")[0]\n",
    "    df = pd.read_csv(os.path.join(data_dir, file))\n",
    "\n",
    "    total_gets = df[\"Total GET messages\"].max()\n",
    "    failed_gets = df[\"Total failed GETs\"].max()\n",
    "    successful_gets = total_gets - failed_gets\n",
    "    new_row = pd.DataFrame([[peer_id, total_gets, failed_gets, successful_gets]], columns=[\"peer_id\", \"total_gets\", \"failed_gets\", \"successful_gets\"])\n",
    "\n",
    "    total_stats_df = pd.concat([\n",
    "        total_stats_df,\n",
    "        new_row\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(\n",
    "    total_stats_df[\"peer_id\"], \n",
    "    total_stats_df[\"failed_gets\"], \n",
    "    label=\"Failed GETs (Avg. \" + str(round(total_stats_df[\"failed_gets\"].mean())) + \")\",\n",
    "    width=0.5  # Make the bars thinner\n",
    ")\n",
    "plt.bar(\n",
    "    total_stats_df[\"peer_id\"], \n",
    "    total_stats_df[\"successful_gets\"], \n",
    "    label=\"Successful GETs (Avg. \" + str(round(total_stats_df[\"successful_gets\"].mean())) + \")\",\n",
    "    width=0.5  # Make the bars thinner\n",
    ")\n",
    "plt.xlabel(\"Peer ID\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Total Failed Gets and Successful Gets per Peer\")\n",
    "\n",
    "# Show the number of successful gets on top of the bar\n",
    "for i, successful_gets in enumerate(total_stats_df[\"successful_gets\"]):\n",
    "    plt.text(i, successful_gets, str(successful_gets), ha='center', va='bottom', color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Validator PUT/GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? Get all nonvalidators total stats\n",
    "nonvalidator_total_stats_files = [file for file in os.listdir(data_dir) if file.endswith('total_stats_nonvalidator.csv')]\n",
    "\n",
    "total_stats_df = pd.DataFrame(columns=[\"peer_id\", \"total_gets\", \"failed_gets\", \"successful_gets\"])\n",
    "\n",
    "for file in nonvalidator_total_stats_files:\n",
    "    peer_id = file.split(\"_\")[0]\n",
    "    df = pd.read_csv(os.path.join(data_dir, file))\n",
    "\n",
    "    total_gets = df[\"Total GET messages\"].max()\n",
    "    failed_gets = df[\"Total failed GETs\"].max()\n",
    "    successful_gets = total_gets - failed_gets\n",
    "    new_row = pd.DataFrame([[peer_id, total_gets, failed_gets, successful_gets]], columns=[\"peer_id\", \"total_gets\", \"failed_gets\", \"successful_gets\"])\n",
    "\n",
    "    total_stats_df = pd.concat([\n",
    "        total_stats_df,\n",
    "        new_row\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(\n",
    "    total_stats_df[\"peer_id\"], \n",
    "    total_stats_df[\"failed_gets\"], \n",
    "    label=\"Failed GETs (Avg. \" + str(round(total_stats_df[\"failed_gets\"].mean())) + \")\",\n",
    "    width=0.5  # Make the bars thinner\n",
    ")\n",
    "plt.bar(\n",
    "    total_stats_df[\"peer_id\"], \n",
    "    total_stats_df[\"successful_gets\"], \n",
    "    label=\"Successful GETs (Avg. \" + str(round(total_stats_df[\"successful_gets\"].mean())) + \")\",\n",
    "    width=0.5  # Make the bars thinner\n",
    ")\n",
    "plt.xlabel(\"Peer ID\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Total Failed Gets and Successful Gets per Peer\")\n",
    "\n",
    "# Show the number of successful gets on top of the bar\n",
    "for i, successful_gets in enumerate(total_stats_df[\"successful_gets\"]):\n",
    "    plt.text(i, successful_gets, str(successful_gets), ha='center', va='bottom', color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latencies Per Peer Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "validator_latency_files = [file for file in os.listdir(data_dir) if file.endswith('latency_stats_validator.csv')]\n",
    "\n",
    "total_stats_df = pd.DataFrame(columns=[\"peer_id\", \"get_latencies\"])\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 15))\n",
    "\n",
    "for file in validator_latency_files:\n",
    "    peer_id = file.split(\"_\")[0]\n",
    "    df = pd.read_csv(os.path.join(data_dir, file))\n",
    "\n",
    "    total_gets = df[\"GET latencies (us)\"]\n",
    "    running_avg = total_gets.rolling(window=10).mean()\n",
    "    axes[0].plot(total_gets, label=peer_id)\n",
    "    axes[1].plot(running_avg, label=peer_id)\n",
    "    sns.kdeplot(total_gets, ax=axes[2], label=peer_id)\n",
    "    sns.kdeplot(total_gets, ax=axes[3], label=peer_id)\n",
    "\n",
    "axes[0].set_xlabel(\"Increasing Time\")\n",
    "axes[0].set_ylabel(\"Latency (us)\")\n",
    "axes[0].legend()\n",
    "axes[0].set_title(\"GET Latencies\")\n",
    "\n",
    "axes[1].set_xlabel(\"Increasing Time\")\n",
    "axes[1].set_ylabel(\"Latency (us)\")\n",
    "axes[1].legend()\n",
    "axes[1].set_title(\"Running Average of GET Latencies\")\n",
    "\n",
    "axes[2].set_xlabel(\"Latency (us)\")\n",
    "axes[2].set_ylabel(\"Density\")\n",
    "axes[2].legend()\n",
    "axes[2].set_title(\"Kernel Density Estimation of GET Latencies\")\n",
    "\n",
    "axes[3].set_xlabel(\"Latency (us)\")\n",
    "axes[3].set_ylabel(\"Density\")\n",
    "axes[3].set_xlim(0, 2000)\n",
    "axes[3].legend()\n",
    "axes[3].set_title(\"Zoomed In: Kernel Density Estimation of GET Latencies\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "latency_files = [file for file in os.listdir(data_dir) if file.endswith('latency_stats_nonvalidator.csv')]\n",
    "\n",
    "total_stats_df = pd.DataFrame(columns=[\"peer_id\", \"get_latencies\"])\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 15))\n",
    "\n",
    "for file in latency_files:\n",
    "    peer_id = file.split(\"_\")[0]\n",
    "    df = pd.read_csv(os.path.join(data_dir, file))\n",
    "\n",
    "    total_gets = df[\"GET latencies (us)\"]\n",
    "    running_avg = total_gets.rolling(window=10).mean()\n",
    "    axes[0].plot(total_gets, label=peer_id)\n",
    "    axes[1].plot(running_avg, label=peer_id)\n",
    "    sns.kdeplot(total_gets, ax=axes[2], label=peer_id)\n",
    "    sns.kdeplot(total_gets, ax=axes[3], label=peer_id)\n",
    "\n",
    "axes[0].set_xlabel(\"Increasing Time\")\n",
    "axes[0].set_ylabel(\"Latency (us)\")\n",
    "axes[0].legend()\n",
    "axes[0].set_title(\"GET Latencies\")\n",
    "\n",
    "axes[1].set_xlabel(\"Increasing Time\")\n",
    "axes[1].set_ylabel(\"Latency (us)\")\n",
    "axes[1].legend()\n",
    "axes[1].set_title(\"Running Average of GET Latencies\")\n",
    "\n",
    "axes[2].set_xlabel(\"Latency (us)\")\n",
    "axes[2].set_ylabel(\"Density\")\n",
    "axes[2].legend()\n",
    "axes[2].set_title(\"Kernel Density Estimation of GET Latencies\")\n",
    "\n",
    "axes[3].set_xlabel(\"Latency (us)\")\n",
    "axes[3].set_ylabel(\"Density\")\n",
    "axes[3].set_xlim(0, 2000)\n",
    "axes[3].legend()\n",
    "axes[3].set_title(\"Zoomed In: Kernel Density Estimation of GET Latencies\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Time per Peer Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "latency_files = [file for file in os.listdir(data_dir) if file.endswith('latency_stats_validator.csv')]\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 10))\n",
    "\n",
    "for file in latency_files:\n",
    "    df = pd.read_csv(os.path.join(data_dir, file))\n",
    "\n",
    "    row_sampling_latencies_sec = df[\"Row Sampling Latencies (us)\"] / 1_000_000\n",
    "    col_sampling_latencies_sec = df[\"Col Sampling Latencies (us)\"] / 1_000_000\n",
    "    random_sampling_latencies_sec = df[\"Random Sampling Latencies (us)\"] / 1_000_000\n",
    "    \n",
    "    total_lat_us = []\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        row_lat_us = row[1][\"Row Sampling Latencies (us)\"]\n",
    "        col_lat_us = row[1][\"Col Sampling Latencies (us)\"]\n",
    "        rand_lat_us = row[1][\"Random Sampling Latencies (us)\"]\n",
    "        total_lat_us.append(row_lat_us + col_lat_us + rand_lat_us)\n",
    "        \n",
    "\n",
    "    total_lat_sec = np.array(total_lat_us) / 1_000_000\n",
    "\n",
    "    axes[0].plot(row_sampling_latencies_sec, label=file.split(\"_\")[0], marker=\"o\", linestyle=\"none\")\n",
    "    axes[1].plot(col_sampling_latencies_sec, label=file.split(\"_\")[0], marker=\"o\", linestyle=\"none\")\n",
    "    axes[2].plot(random_sampling_latencies_sec, label=file.split(\"_\")[0], marker=\"o\", linestyle=\"none\")\n",
    "    axes[3].plot(total_lat_sec, label=file.split(\"_\")[0], marker=\"o\", linestyle=\"none\")\n",
    "\n",
    "axes[0].set_title(\"Row Sampling Latencies\")\n",
    "axes[1].set_title(\"Col Sampling Latencies\")\n",
    "axes[2].set_title(\"Random Sampling Latencies\")\n",
    "axes[2].set_title(\"Total Sampling Latencies\")\n",
    "\n",
    "axes[3].axhline(y=4, color='red', linestyle='--', label=\"4 sec requirement\")\n",
    "axes[3].axhline(y=12, color='purple', linestyle='--', label=\"12 sec requirement\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Sampled Block Over Increasing Time\")\n",
    "    ax.set_ylabel(\"Time Taken to Sample (s)\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
